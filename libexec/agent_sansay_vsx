#!/usr/bin/env python3
# -*- encoding: utf-8; py-indent-offset: 4 -*-
"""special agent call to retrieve API info from Sansay VSX device"""

# License: GNU General Public License v2


import requests
from requests.auth import HTTPBasicAuth
import argparse

from cmk.special_agents.v0_unstable.agent_common import SectionWriter

requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)


def parse_args():
    parser = argparse.ArgumentParser(
        prog = 'sansay-vsx',
        description = 'Special Agent to query metrics and performance from Sansay VSX devices.',
        epilog = 'A work in progress written for CheckMK but desired to run standalone for testing.'
        )
    parser.add_argument('-u', '--username',
                        help='Username of the API credentials.',
                        nargs='?')
    parser.add_argument('-p', '--password',
                        help='Password of the API credentials.',
                        nargs='?',)
    parser.add_argument('-i', '--ignoressl',
                        help='Ignore SSL security checks.',
                        action='store_true')
    parser.add_argument('-v', '--verbose',
                        action='store_true',
#                        default=True)
                        default=False)
    parser.add_argument("host",
                        metavar="HOSTNAME",
                        help="IP address or hostname of your Sansay VSX API capabale device.",)
    return parser.parse_args()


def fetch_sansay_json(report_name):
    if args.verbose:
        print(f"[{device}] -> fetching Sansay VSX {report_name} stats")

    url = f"https://{device}:8888/SSConfig/webresources/stats/{report_name}"
    params = {
        "format": "json"
    }
    username = args.username
    password = args.password
    ssl_verify = args.ignoressl
    
    if ssl_verify and args.verbose:
        print(f"[{device}] -> WARN: hostname/certificate verification disabled via {args.ignoressl} parameter.")
    
    if not username or not password:
        print(f"[{device}] -> ERROR: unable to fetch Sansay report, VSX username/password parameter missing")
        return None

    try:
        response = requests.get(
            url,
            auth=HTTPBasicAuth(username, password),
            params=params,
            verify=ssl_verify,
            timeout=90
        )
        if ssl_verify and args.verbose:
            print(f"[{device}] -> fetching Sansay VSX {report_name} stats (complete)")

        if response.status_code != 200:
            print(f"[{device}] -> ERROR: unable to fetch Sansay '{report_name}' report: {response.status_code} {response.reason}")
            return None
        return response.json()
    except requests.RequestException as e:
        print(f"[{device}] -> ERROR: unable to fetch Sansay '{report_name}' report: {e}")
        return None


def poll_sansay_vsx():
    """
    Define the framework stats to return and poll the Sansay to retrieve data:
      - resource - all trunks with their ingress and egress data
      - realtime - overall VSX stats plus active trunks realtime data
      - media_server - media server statistics
    """
    stats = {}

    resource_data = fetch_sansay_json("resource")
    if resource_data is not None:
        stats["trunks"] = process_resource_data(resource_data)

    realtime_data = fetch_sansay_json("realtime")
    if realtime_data is not None:
        realtime_system_data, realtime_trunk_data = process_realtime_data(realtime_data)
        #stats["system_stat"].update(realtime_system_data["system_stat"])
        stats["system_stat"] = realtime_system_data["system_stat"]
        stats["trunks"].update(process_realtime_trunk_data(stats["trunks"],realtime_trunk_data))

    media_data = fetch_sansay_json("media_server")
    if media_data is not None:
        stats["media_stats"] = process_media_data(media_data)

    return stats


def process_resource_data(data):
    if data is None:
        print(f"[{device}] -> unable to parse table from json response data.\n{data}")
        return
    
    trunks = {}
    tables = data["mysqldump"]["database"]["table"]
    for table in tables:
        if args.verbose:
            print(f"Processing entries in {table}.")

        for row in table["row"]:
            # Convert the list dictionaries with name and content values into
            # a single dictionary with the name as key and content as value.
            row_dict = {field["name"]: field["content"] for field in row["field"]}
            recid = row_dict.pop("id")
            trunk_id = row_dict.pop("trunk_id")
            alias = row_dict.pop("alias")
            if args.verbose:
                print(f"[{device}] -> Processing row data {row}")
                print(f"[{device}] -> Conversion to {row_dict=}")
            
            # If the trunk ID isn't in the stats, add it.
            if trunk_id not in trunks.keys():
                if args.verbose:
                    print(f"[{device}] -> {trunk_id} not found in stats table.")
                trunks[trunk_id] = {}
                trunks[trunk_id]["recid"] = recid
                trunks[trunk_id]["alias"] = alias
                if args.verbose:
                    print(f"[{device}] -> Created entry for {trunks[trunk_id]} with alias {trunks[trunk_id]['alias']}.")

            # If table name isn't in dictionary keys, add it to separate ingress and egress stats.
            if table["name"] not in trunks[trunk_id].keys():
                if args.verbose:
                    print(f"[{device}] -> {table} not found in stats trunks table.")
                trunks[trunk_id][table["name"]] = row_dict
                if args.verbose:
                    print(f"[{device}] -> Created key for {table['name']} and value of metrics: {row_dict}.")

    if args.verbose:
        pprint(f"resource {trunks=}")
    return trunks


def process_realtime_data(data):
    if data is None:
        print(f"[{device}] -> unable to parse table from json response data.\n{data}")
        return

    tables = data["mysqldump"]["database"]["table"]
    table_count = 0
    system_stat = {}
    trunk_realtime_data = {}
    for table in tables:
        table_count += 1
        table_name = table["name"]
        if args.verbose:
            print(f"[{device}] -> processing table #{table_count} '{table_name}' stats from json response data.")
        if table_name == "system_stat":
            row_dict = {field["name"]: field["content"] for field in table["row"]["field"]}
            system_stat[table_name] = row_dict
        elif table_name == "XBResourceRealTimeStatList":
            # Fetch the row value and if it's not present, return an empty list.
            # This happens due to the device only sending active trunks.
            #rows = table.get("row",list())
            rows = table.get("row",None)
            if rows:
                for row in rows:
                    realtime_row_dict = {fieldrow["name"]: fieldrow["content"] for fieldrow in row["field"]}
                    ## Ignore realtime trunk data that has the FQDN noted as a group
                    if realtime_row_dict["fqdn"] != "Group":
                        trunk_realtime_data[realtime_row_dict["trunkId"]] = {fieldrow["name"]: fieldrow["content"] for fieldrow in row["field"]}
    return system_stat, trunk_realtime_data


def process_realtime_trunk_data(trunks, realtime_data):
    """
    Add a realtime_stat value to every trunk updating any with 
    realtime_data provided otherwise default to 0 for the polling
    interval.
    """

    for trunk in trunks.keys():
        trunks[trunk]["realtime_stat"] = {}
        trunks[trunk]["realtime_stat"]["numOrig"] = realtime_data.get(trunk, {}).get("numOrig", 0)
        trunks[trunk]["realtime_stat"]["numTerm"] = realtime_data.get(trunk, {}).get("numTerm", 0)
        trunks[trunk]["realtime_stat"]["cps"] = realtime_data.get(trunk, {}).get("cps", 0)
        trunks[trunk]["realtime_stat"]["numPeak"] = realtime_data.get(trunk, {}).get("numPeak", 0)
        trunks[trunk]["realtime_stat"]["totalCLZ"] = realtime_data.get(trunk, {}).get("totalCLZ", 0)
        trunks[trunk]["realtime_stat"]["numCLZCps"] = realtime_data.get(trunk, {}).get("numCLZCps", 0)
        trunks[trunk]["realtime_stat"]["totalLimit"] = realtime_data.get(trunk, {}).get("totalLimit", 0)
        trunks[trunk]["realtime_stat"]["cpsLimit"] = realtime_data.get(trunk, {}).get("cpsLimit", 0)

    return trunks


def process_media_data(media_data):
    if media_data is None:
        print(f"[{device}] -> unable to parse XBMediaServerRealTimeStat from jsondata: {media_data}")
        return
    media_servers = media_data["XBMediaServerRealTimeStatList"]["XBMediaServerRealTimeStat"]
    return media_servers


def process_media_stats(stats):
    if "media_stats" not in stats:
        print(f"[{device}] -> No media stats found in jsondata: {stats}")
        return None
    return stats["media_stats"]


def process_trunk_stats(stats):
    if "trunks" not in stats:
        print(f"[{device}] -> No trunk stats found in jsondata: {stats}")
        return None

    for trunk, data in stats["trunks"].items():
        default_stats = {
            'ingress': {
                'avg_postdial_delay': 0,
                'avg_call_duration': 0,
                'failed_call_ratio': 0,
                'answer_seize_ratio': 0,
            },
            'egress': {
                'avg_postdial_delay': 0,
                'avg_call_duration': 0,
                'failed_call_ratio': 0,
                'answer_seize_ratio': 0,
            },
            'realtime': {
                'origination_sessions': 0,
                'origination_utilization': 0,
                'termination_sessions': 0,
                'termination_utilization': 0,
            },
        }
        calculated_stats = default_stats

        # Realtime stat calculations for the trunk
        origination_sessions = int(data["realtime_stat"].get('numOrig', 0))
        termination_sessions = int(data["realtime_stat"].get('numTerm', 0))
        total_limit = int(data["realtime_stat"].get('totalLimit', 0))
        origination_utilization = termination_utilization = 0
        if total_limit:
            origination_utilization = round((origination_sessions / total_limit) * 100, 1)
            termination_utilization = round((termination_sessions / total_limit) * 100, 1)

        calculated_stats["realtime"] = {
            'origination_sessions': origination_sessions,
            'origination_utilization': origination_utilization,
            'termination_sessions': termination_sessions,
            'termination_utilization': termination_utilization,
        }
        stats["trunks"][trunk].pop("realtime_stat")

        # Ingress and Egress calculations for the trunk
        for direction in ["ingress_stat", "gw_egress_stat"]:
            PDDms = float(data[direction].get('1st15mins_pdd_ms', 0))
            CA = float(data[direction].get('1st15mins_call_attempt', 0))
            CD = float(data[direction].get('1st15mins_call_durationSec', 0))
            FC = float(data[direction].get('1st15mins_call_fail', 0))
            CAns = float(data[direction].get('1st15mins_call_answer', 0))

            if CA > 0:
                calculated_stats[direction] = {
                    'avg_postdial_delay': round((PDDms / CA) / 1000, 1),
                    'avg_call_duration': round(CD / CA, 1),
                    'failed_call_ratio': round((FC / CA) * 100, 1),
                    'answer_seize_ratio': round((CAns / CA) * 100, 1),
                }
            stats["trunks"][trunk].pop(direction)
        
        stats["trunks"][trunk]["calculated_stats"] = calculated_stats
        #print(f"{trunk} {data['alias']} - {data['calculated_stats']}")
    return stats["trunks"]


def process_system_stats(stats):
    if "system_stat" not in stats:
        print(f"[{device}] -> No media stats found in jsondata: {stats}")
        return
    
    return stats["system_stat"]


if __name__ == "__main__":
    args = parse_args()
    device = args.host
    if args.verbose:
        print(f'DEBUG: {args.device =}')
        print(f'DEBUG: {args.username =}')
        print(f'DEBUG: {args.password =}')
        print(f'DEBUG: {args.verbose =}')
        print(f"DEBUG: {type(device)}\n{device =}")

    stats = poll_sansay_vsx()
    # print("<<<sansay_vsx_media:sep(0)>>>")
    # print("[{'mediaSrvIndex': 1, 'switchType': 'Internal Media Switching', 'alias': 'Internal Media Switching', 'numActiveSessions': 0, 'publicIP': '209.55.10.4', 'priority': 2, 'maxConnections': 3000, 'status': 'up'}, {'mediaSrvIndex': 2, 'switchType': 'External Advanced Hybrid-Media Switching', 'alias': 'MST3 HA Pair', 'numActiveSessions': 6, 'publicIP': '209.55.10.7', 'priority': 0, 'maxConnections': 8000, 'status': 'up'}, {'mediaSrvIndex': 3, 'switchType': 'Advanced Hybrid-MLT', 'alias': 'MLT transcoder', 'numActiveSessions': 0, 'publicIP': '209.55.10.7', 'priority': 0, 'maxConnections': 2000, 'status': 'up'}]")
    # print(process_media_stats(stats))
    with SectionWriter("sansay_vsx_media") as writer:
        writer.append_json(process_media_stats(stats))
    with SectionWriter("sansay_vsx_trunks") as writer:
        writer.append_json(process_trunk_stats(stats))
    with SectionWriter("sansay_vsx_system") as writer:
        writer.append_json(process_system_stats(stats))
    # print("<<<sansay_vsx_trunks:sep(0)>>>")
    # print("{'trunks': {1: {'recid': 1,'alias': 'ATL-PHL VSXs','ingress_stat': {'1st15mins_call_attempt': 0,'1st15mins_call_answer': 0,'1st15mins_call_fail': 0,'1h_call_attempt': 1,'1h_call_answer': 1,'1h_call_fail': 0,'24h_call_attempt': 25,'24h_call_answer': 18,'24h_call_fail': 5,'1st15mins_call_durationSec': 0,'1h_call_durationSec': 102,'24h_call_durationSec': 3050,'1st15mins_pdd_ms': 0,'1h_pdd_ms': 1000,'24h_pdd_ms': 16000},'gw_egress_stat': {'1st15mins_call_attempt': 3,'1st15mins_call_answer': 3,'1st15mins_call_fail': 0,'1h_call_attempt': 18,'1h_call_answer': 18,'1h_call_fail': 0,'24h_call_attempt': 242,'24h_call_answer': 204,'24h_call_fail': 15,'1st15mins_call_durationSec': 164,'1h_call_durationSec': 1891,'24h_call_durationSec': 56628,'1st15mins_pdd_ms': 5350,'1h_pdd_ms': 26910,'24h_pdd_ms': 507010},'realtime_stat': {'numOrig': 0,'numTerm': 3,'cps': 0,'numPeak': 4,'totalCLZ': 3,'numCLZCps': 0,'totalLimit': 2000,'cpsLimit': 100},'calculated_stats': {'ingress': {'avg_postdial_delay': 0,'avg_call_duration': 0,'failed_call_ratio': 0,'answer_seize_ratio': 0},'egress': {'avg_postdial_delay': 0,'avg_call_duration': 0,'failed_call_ratio': 0,'answer_seize_ratio': 0},'realtime': {'origination_sessions': 0,'origination_utilization': 0.0,'termination_sessions': 3,'termination_utilization': 0.1},'gw_egress_stat': {'avg_postdial_delay': 1.8,'avg_call_duration': 54.7,'failed_call_ratio': 0.0,'answer_seize_ratio': 100.0}}}}}")
    # print(process_trunk_stats(stats))
    # print("<<<sansay_vsx_system:sep(0)>>>")
    # print("{'id': 1, 'sum_active_session': 6, 'sum_attempt_session': 26498, 'peak_active_session': 23, 'max_session_allowed': 19750, 'max_session_exceed': 0, 'inbound_sip_leg': 6, 'outbound_sip_leg': 6, 'peak_sip_leg': 46, 'inbound_h323_leg': 0, 'outbound_h323_leg': 0, 'peak_h323_leg': 0, 'cpu_idle_percent': 99, 'flow_control_lev': 0, 'cluster_active_session': 6, 'cluster_peak_session': 23, 'demo_lic': -1, 'slave_stat': 64, 'ha_pre_state': 'standby', 'ha_current_state': 'active', 'ha_remote_status': 0, 'switch_over_flag': 3, 'ha_local_status': 0, 'max_cps_allowed': 10000, 'max_cps_exceed': 0, 'current_cps': 0}")
    # print(process_system_stats(stats))
